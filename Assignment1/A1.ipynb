{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akshatgupta/Desktop/IIITD/SEM_6/DL/DL-Assignments/Assignment1/mnist_data\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9680k  100 9680k    0     0  4602k      0  0:00:02  0:00:02 --:--:-- 4602k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28881  100 28881    0     0  70208      0 --:--:-- --:--:-- --:--:-- 70099\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1610k  100 1610k    0     0   634k      0  0:00:02  0:00:02 --:--:--  634k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4542  100  4542    0     0   7668      0 --:--:-- --:--:-- --:--:--  7659\n",
      "/Users/akshatgupta/Desktop/IIITD/SEM_6/DL/DL-Assignments/Assignment1\n"
     ]
    }
   ],
   "source": [
    "!rm -rf mnist_data\n",
    "!mkdir mnist_data\n",
    "%cd mnist_data\n",
    "\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "!gunzip *.gz\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def tensor_transform(data):\n",
    "    return torch.from_numpy(data).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, struct\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self,root,train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (str): path to the directory of the dataset\n",
    "            train (bool, default=True): if True return training data, else return testing data\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "\n",
    "        self.data_name = ('train-images-idx3-ubyte' if train else 't10k-images-idx3-ubyte')\n",
    "        self.labels_name = ('train-labels-idx1-ubyte' if train else 't10k-labels-idx1-ubyte')\n",
    "        self.data, self.labels = self.load_data()\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        data_path = os.path.join(self.root, self.data_name)\n",
    "        labels_path = os.path.join(self.root, self.labels_name)\n",
    "\n",
    "        with open(data_path, 'rb') as f:\n",
    "            _, _, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "            data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            data = data.reshape(-1, rows, cols)\n",
    "        with open(labels_path, 'rb') as f:\n",
    "            _, _ = struct.unpack('>II', f.read(8))\n",
    "            labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img, target = list(self.data[index].reshape(1,28,28)), int(self.labels[index])\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader:\n",
    "    def __init__(self,dataset,batch_size=64,shuffle=False,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (obj): Dataset object that will be loaded into the stream; must implement __getitem__ and __len__ functions\n",
    "            batch_size (int, default=64): batch size\n",
    "            shuffle (bool, default=False): if True shuffles the data before loading into stream\n",
    "            transform (callable, default=None): transform function to apply to data\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.transform = transform\n",
    "        self.num_samples = len(dataset)\n",
    "        self.num_batches = (self.num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            indices = torch.randperm(self.num_samples)\n",
    "        else:\n",
    "            indices = torch.arange(self.num_samples)\n",
    "\n",
    "        for i in range(0, self.num_samples, self.batch_size):\n",
    "            batch_indices = indices[i:min(self.num_samples,i+self.batch_size)]\n",
    "            batch = [self.dataset[index] for index in batch_indices]\n",
    "            batch = tuple(zip(*batch))\n",
    "            data, label = batch\n",
    "\n",
    "            if self.transform is not None:\n",
    "                data = self.transform(np.array(data))\n",
    "\n",
    "            yield {'data':data,'label':label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CustomDataset(\n",
    "    root=\"./mnist_data/\",\n",
    "    train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = CustomDataLoader(\n",
    "    dataset=data,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    transform=tensor_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.dataset = datasets.MNIST(root=root, train=True, transform=transform, download=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        return {'data': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 3880066.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1073336.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1108106.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 3435622.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "mnist_data = MNISTDataset(root=\"./mnist_data/\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "mnist_dataloader = DataLoader(mnist_data,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
